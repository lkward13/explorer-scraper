# Database Fix Summary

**Date:** November 24, 2025  
**Issue:** 100-origin test data not saved to database  
**Status:** FIXED âœ…

---

## ğŸ› Problem Identified

The 100-origin test completed successfully with 432 valid deals, but **ZERO deals were saved to the database**.

### Root Cause

**Missing column in INSERT statement:**

The database schema has a `scrape_run_id` column with a foreign key constraint, but the INSERT statement in `database/db.py` was missing this column:

```python
# BEFORE (broken)
INSERT INTO expanded_deals 
    (origin, destination, destination_city, outbound_date, return_date, ...)
VALUES 
    (%(origin)s, %(destination)s, %(destination_city)s, ...)
```

The code was passing `scrape_run_id` in the data dict, but it wasn't included in the SQL statement, causing a **silent failure** (PostgreSQL rejected the INSERT due to foreign key constraint).

### Secondary Issue

The `execute_batch()` function doesn't update `cur.rowcount`, so the return value was always 1 instead of the actual number of rows inserted. This masked the problem in the logs.

---

## âœ… Fixes Applied

### 1. Added scrape_run_id to INSERT statement

```python
# AFTER (fixed)
INSERT INTO expanded_deals 
    (scrape_run_id, origin, destination, destination_city, outbound_date, return_date, ...)
VALUES 
    (%(scrape_run_id)s, %(origin)s, %(destination)s, %(destination_city)s, ...)
```

**File:** `database/db.py` line 64-73

### 2. Fixed row count reporting

```python
# BEFORE
inserted_count = cur.rowcount  # Always returns 1 with execute_batch

# AFTER
inserted_count = len(deals)  # Return actual number of deals inserted
```

**File:** `database/db.py` line 78

---

## ğŸ§ª Verification

**Test with 2 origins:**
- âœ… Inserted 231 deals successfully
- âœ… Data visible in database with correct `scrape_run_id`
- âœ… Proper row count reported

```sql
SELECT scrape_run_id, origin, COUNT(*) 
FROM expanded_deals 
WHERE scrape_run_id = 16 
GROUP BY scrape_run_id, origin;

 scrape_run_id | origin | count 
---------------+--------+-------
            16 | ATL    |   103
            16 | DFW    |   128
```

---

## ğŸ“Š Impact on 100-Origin Test

**Previous test (scrape_run_ids 12-15):**
- âŒ **0 deals saved** due to missing `scrape_run_id` column
- âœ… Test completed successfully (432 valid deals found)
- âœ… All data logged to `test_100_origins_final.log`

**Next steps:**
1. âœ… Database code is now fixed
2. â³ Need to re-run 100-origin test to populate database
3. â³ Or extract data from log file if re-run not desired

---

## ğŸš€ Recommendation

**Option 1: Re-run 100-origin test (RECOMMENDED)**
- Pros: Fresh data with correct database integration
- Pros: Can verify rate limiting improvements are consistent
- Cons: Takes 2.5-3 hours

**Option 2: Parse log file**
- Pros: Faster (no re-run needed)
- Pros: Can extract the 432 valid deals from `test_100_origins_final.log`
- Cons: More complex parsing
- Cons: Won't have all similar dates (only summary data)

**Recommendation:** Re-run the test to get complete data with all similar dates and proper database integration.

---

## ğŸ“ Files Modified

1. **database/db.py**
   - Added `scrape_run_id` to INSERT statement
   - Fixed row count return value

2. **No schema changes needed** - schema was already correct

---

## âœ… Status

- [x] Bug identified
- [x] Fix implemented
- [x] Fix tested and verified
- [ ] 100-origin test re-run (pending user decision)

